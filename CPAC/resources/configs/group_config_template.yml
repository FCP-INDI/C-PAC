# CPAC Group-Level Analysis Configuration YAML file
# Version 1.8.7.dev1
#
# http://fcp-indi.github.io for more info.
#
# Tip: This file can be edited manually with a text editor for quick modifications.


# General Group-Level Analysis Settings

pipeline_setup:

  # Name for this pipeline configuration - useful for identification.
  pipeline_name: cpac-group-template

  output_directory:

    # The main input of group-level analysis- the output directory of your individual-level analysis pipeline run (pre-processing & derivatives for each participant). This should be a path to your C-PAC individual-level run's pipeline folder, which includes the sub-directories labeled with the participant IDs.
    source_outputs_path : /source_output

    # (Optional) Full path to a list of participants to be included in the model. You can use this to easily prune participants from your model. In group-level analyses involving phenotype files, this allows you to prune participants without removing them from the phenotype CSV/TSV file. This should be a text file with one subject per line. An easy way to manually create this file is to copy the participant ID column from your phenotype file.
    participant_list: None

    # Full path to the directory where CPAC should place group-level analysis outputs and any applicable statistical model files.
    output_path: /output

  working_directory:

    #Much like the working directory for individual-level analysis, this is where the intermediate and working files will be stored during your run. This directory can be deleted later on. However, saving this directory allows the group analysis run to skip steps that have been already completed, in the case of re-runs.
    path: /tmp

    #Deletes the contents of the Working Directory after running.
    # This saves disk space, but any additional preprocessing or analysis will have to be completely re-run.
    remove_working_dir: True

  log_directory:
    
    # Whether to write log details of the pipeline run to the logging files.
    run_logging: True

    #Where to write out log information for your group analysis run.
    path: /logs

  crash_log_directory:

    # Directory where CPAC should write crash logs.
    path: /crash

  system_config:

    # The path to your FSL installation directory. This can be left as 'FSLDIR' to grab your system's default FSL installation. However, if you prefer to use a specific install of FSL, you can enter the path here.
    FSLDIR: FSLDIR

    # Number of CPUs to dedicate to the group-level analysis run. Parallelizes the pipeline where applicable.
    num_cpus: 1

    # The maximum amount of memory each participant's workflow can allocate.
    # Use this to place an upper bound of memory usage.
    # - Warning: 'Memory Per Participant' multiplied by 'Number of Participants to Run Simultaneously'
    #   must not be more than the total amount of RAM.
    # - Conversely, using too little RAM can impede the speed of a pipeline run.
    # - It is recommended that you set this to a value that when multiplied by
    #   'Number of Participants to Run Simultaneously' is as much RAM you can safely allocate.
    num_memory: 10

    # Scan inclusion list. For most group-level analyses, a separate model is run for each scan/series in your individual-level analysis pipeline directory.
    # Use this list to prune your run to only specific scans.
    # Example:
    # scan_inclusion: ['rest_run-1', 'rest_run-2']
    scan_inclusion: []

  Amazon-AWS:

    # If setting the 'Output Directory' to an S3 bucket, insert the path to your AWS credentials file here.
    aws_output_bucket_credentials:

    # Enable server-side 256-AES encryption on data to the S3 bucket
    s3_encryption: False

  Debugging:

    # Verbose developer messages.
    verbose: Off


# FSL-FEAT

fsl_feat:

  # Run FSL FEAT group-level analysis.
  run:  Off

  # How many statistical models to run in parallel. This number depends on computing resources.
  num_models_at_once:  1

  # Specify a name for the new model.
  model_name: model_name_here

  # Phenotype file
  # Full path to a .csv or .tsv file containing EV/regressor information for each subject.
  pheno_file: /path

  # Name of the participants column in your phenotype file.
  participant_id_label: Participant

  # Specify which EVs from your phenotype are categorical or numerical. Of those which are numerical, specify which are to be demeaned.
  # ev_selections: {'demean': ['Age'], 'categorical': ['Sex', 'Diagnosis']}
  ev_selections: {'demean': [], 'categorical': []}

  # Specify the formula to describe your model design. Essentially, including EVs in this formula inserts them into the model. The most basic format to include each EV you select would be 'EV + EV + EV + ..', etc. You can also select to include MeanFD, Measure_Mean, and Custom_ROI_Mean here. See the C-PAC User Guide for more detailed information regarding formatting your design formula.
  # design_formula: Sex + Diagnosis + Age + MeanFD_Jenkinson + Custom_ROI_Mean
  design_formula:

  # Choose the derivatives to run the group model on.
  #
  # These must be written out as a list, and must be one of the options listed below.
  #
  # For z-scored analyses:
  # 'desc-zstd_alff', 'desc-sm-zstd_alff', 'desc-zstd_falff', 'desc-sm-zstd_falff', 'desc-zstd_reho', 'desc-sm-zstd_reho', 'desc-zstd_sca_roi', 'desc-sm-zstd_sca_roi', 'desc-zstd_vmhc', 'desc-zstd_dr_tempreg_maps', 'desc-sm-zstd_dr_tempreg_maps', 'desc-zstd_sca_tempreg_maps', 'desc-sm-zstd_sca_tempreg_maps', 'desc-zstd_centrality', 'desc-sm-zstd_centrality'
  #
  # Example input: derivative_list :  ['desc-sm-zstd_alff', 'desc-sm-zstd_sca_roi']
  #
  derivative_list: []

  # Choose whether to use a group mask or individual-specific mask when calculating the output means to be used as a regressor.
  #
  # This only takes effect if you include the 'Measure_Mean' regressor in your Design Matrix Formula.
  mean_mask: ['Group Mask']

  # Full path to a NIFTI file containing one or more ROI masks. The means of the masked regions will then be computed for each subject's output and will be included in the model as regressors (one for each ROI in the mask file) if you include 'Custom_ROI_Mean' in the Design Matrix Formula.
  # custom_roi_mask: /path/to/mask.nii.gz
  custom_roi_mask: None

  # Choose the coding scheme to use when generating your model. 'Treatment' encoding is generally considered the typical scheme. Consult the User Guide for more information.
  #
  # Available options:
  # 'Treatment', 'Sum'
  #
  coding_scheme: ['Treatment']

  # Specify whether FSL should model the variance for each group separately.
  #
  # If this option is enabled, you must specify a grouping variable below.
  group_sep: Off

  # The name of the EV that should be used to group subjects when modeling variances.
  #
  # If you do not wish to model group variances separately, set this value to None.
  grouping_var: None

  # Only voxels with a Z-score higher than this value will be considered significant.
  z_threshold: ['2.3']

  # Significance threshold (P-value) to use when doing cluster correction for multiple comparisons.
  p_threshold: ['0.05']

  # For repeated measures only. Enter the session names in your dataset that you wish to include within the same model (this is for repeated measures / within-subject designs).\n\nTip: These will be the names listed as "unique_id" in the original individual-level participant list, or the labels in the original data directories you marked as {session} while creating the CPAC participant list.
  # sessions_list: ['ses-01', 'ses-02']
  sessions_list: []

  # For repeated measures only. Enter the series names in your dataset that you wish to include within the same model (this is for repeated measures / within-subject designs).\n\nTip: These will be the labels listed under "func:" in the original individual-level participant list, or the labels in the original data directories you marked as {series} while creating the CPAC participant list.
  # series_list: ['task-rest_run-1', 'task-rest_run-2']
  series_list: []

  # Specify your contrasts here. For example, if two of your available contrasts are EV1 and EV0, you can enter contrast descriptions such as 'EV1 - EV0 = 0' or 'EV1 = 0'. Consult the User Guide for more information about describing contrasts. Alternatively, you can provide your own custom-written contrasts matrix in a CSV file in the 'Custom Contrasts Matrix' field below.
  # contrasts: ['C(Diagnosis)[T.ADHD] - C(Diagnosis)[T.Typical] = 0', 'C(Diagnosis)[T.Typical] - C(Diagnosis)[T.ADHD] = 0']
  contrasts: []

  # Optional: A list of f-test strings containing contrasts. If you do not wish to run f-tests, leave this blank.
  f_tests: []

  # Optional: Full path to a CSV file which specifies the contrasts you wish to run in group analysis. Consult the User Guide for proper formatting.
  # If you wish to use the standard contrast builder, leave this field blank. If you provide a path for this option, CPAC will use your custom contrasts matrix instead, and will use the f-tests described in this custom file only (ignoring those you have input in the f-tests field above).
  # If you wish to include f-tests, create a new column in your CSV file for each f-test named 'f_test_1', 'f_test_2', .. etc. Then, mark the contrasts you would like to include in each f-test with a 1, and mark the rest 0. Note that you must select at least two contrasts per f-test.
  custom_contrasts: None

# FSL-Randomise
fsl_randomise:

  # Run Randomise
  run:  [0]

  # Number of permutations you would like to use when building up the null distribution to test against.
  permutation:  500

  # Cluster-based thresholding corrected for multiple comparisons by using the null distribution of the max (across the image) cluster mask.
  thresh:  5

  # Demean data temporally before model fitting.
  demean:  True

  # From the FMRIB FSL-Randomise user guide: TFCE (Threshold-Free Cluster Enhancement) is a new method for finding 'clusters' in your data without having to define clusters in a binary way. Cluster-like structures are enhanced but the image remains fundamentally voxelwise.
  tfce:  True


# Bootstrap Analysis of Stable Clusters (BASC) - via PyBASC
basc:

  # Run Bootstrap Analysis of Stable Clusters
  run:  [0]

  # If there are multiple series or scans in any of the pipeline outputs for which PyBASC is being run, and you only want to run for some of them, you can list them here - scan labels separated by commas (ex. 'rest_run-1, rest_run-3').
  # If nothing is listed, all available pipelines will be run.
  scan_inclusion:  None

  # The resolution to run PyBASC with.
  resolution:  4mm

  # Maximum amount of processors to use while performing BASC.
  proc:  2

  # Maximum amount of RAM (in GB) to be used when running BASC.
  memory:  4

  # Standard FSL Skull Stripped Template.
  template_brain_only_for_func:  $FSLDIR/data/standard/MNI152_T1_${basc_resolution}_brain.nii.gz

  # Full path to a mask file to be used when running BASC. Voxels outside this mask will be excluded from analysis. This is the region that youâ€™d like to parcellate.
  # If you do not wish to use a mask, set this field to None.
  # Note: BASC is very computationally intensive, we strongly recommend you limit your analysis to specific brain areas of interest.
  roi_mask_file:  None

  # If cross clustering is enabled, then clustering of the first region will be calculated based on pairwise similarity between the timeseries of the ROI Mask File, and this second ROI.
  cross_cluster_mask_file:  None

  # The metric used to compare similarity between voxel timeseries.
  # Options: ['correlation', 'euclidean', 'cityblock', 'cosine']
  similarity_metric_list:  ['correlation']

  # How many times individual level circular block bootstrapping of the timeseries will be applied.
  timeseries_bootstrap_list:  100

  # Number of bootstraps to apply to the original dataset.
  dataset_bootstrap_list:  30

  # Number of clusters to create during clustering at both the individual and group levels.
  n_clusters_list:  2

  # The similarity threshold at which the similarity matrices will be set to 0.
  affinity_thresh: [0.0]

  # This is the amount of feature agglomeration that will be applied. Smaller values mean more feature agglomeration.
  output_sizes:  800

  # If set to true, then the ROI Mask file parcellation will be based on the similarity between ROI Mask file voxels based on their connectivity to each voxel in ROI mask file for cross-clustering.
  cross_cluster:  True

  # This parameter determines the width of the time window used in the circular block bootstrap.
  blocklength_list:  1

  # If this is set to true, the all individuals will have feature agglomeration applied together, resulting in the same mapping across subjects. Use this only when memory demands limit ability to process ROIs with a high number of voxels.
  group_dim_reduce:  False


# Multivariate Distance Matrix Regression (MDMR)
mdmr:

  # Used to determine if Multivariate Distance Matrix Regression (MDMR) will be added to the pipeline or not.
  run:  [0]

  # Inclusion list text file listing the participant IDs you wish to include in the MDMR analysis. If left as None, will include all subjects.
  inclusion_list : None

  # Path to a mask file. Voxels outside of the mask will be excluded from MDMR.
  roi_file: /path

  # Path to a CSV file containing the phenotypic regressor.
  regressor_file:

  # Name of the participants column in your regressor file.
  regressor_participant_column: ''

  # Columns from the CSV file indicating factor variables. Other columns will be handled as covariates. Separated by commas.
  regressor_columns: ''

  # Number of permutation tests to run on the Pseudo-F statistics.
  permutations:  15000

  # Number of Nipype nodes created while computing MDMR. Dependent upon computing resources.
  parallel_nodes:  10

  # If you want to create zstat maps
  zscore: [1]


# Inter-Subject Correlation (ISC) & Inter-Subject Functional Correlation (ISFC)
isc_isfc:

  # Used to determine if Inter-subject Correlation (ISC) will be added to the pipeline or not.
  runISC: [0]

  # Used to determine if Inter-subject Functional Correlation (ISFC) will be added to the pipeline or not.
  runISFC: [0]

  # Used to determine if the ISC and ISFC will run in the ROI level.
  level_roi: [0]

  # Used to determine if the ISC and ISFC will run in the voxel level. Depending on the image resolution, it may take several hours and consume a great amount of available memory.
  level_voxel: [0]

  # Filter out voxels that, in the correlation distribution, is greater then the informed standard deviation. Zero value will disable the filter.
  level_voxel_std_filter:  0.0

  # Number of permutation tests to compute the statistics.
  permutations:  1000

  # ROI/atlases to include in the analysis. For ROI-level ISC/ISFC runs.
  # This should be a list of names/strings of the ROI names used in individual-level analysis, if ROI timeseries extraction was performed.
  roi_inclusion: [""]


#Quasi Periodic Patterns (QPP)
qpp:

  # Run Quasi Periodic Pattern Analysis
  run: [1]

  scan_inclusion:  

  session_inclusion:  
  
  stratification:

  permutations:  100
  
  window:  30

  initial_threshold: 0.2
  
  final_threshold: 0.3
  
  initial_threshold_iterations :  20

  qpp_iterations :  15
